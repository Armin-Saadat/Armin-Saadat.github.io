- name: 3DPose_Method
  image: images/3D_pose_min.png
  description: |
    ## **Human Pose Prediction: The Simpler The Better!**
    
    ---
    3D human pose prediction is a challenging spatio-temporal task that has been tackled using Graph Convolutional Networks (GCNs), Long Short-Term Memories (LSTMs), and recently Transformers. 
    In this paper, we show that recent complex models are not always effective and still cannot beat a basic baseline that does not involve any learning. 
    Moreover, some classes of human actions are not usefull for models to train on, hence should not be used in the learning process. 
    We propose a simple yet effective LSTM-based encoder-decoder architecture that learns an effective representation for simultaneous prediction of future poses and reconstruction of past ones. 
    We investigate our findings on several standard datasets (Human3.6M, JTA, and 3DPW), and obtain a significant improvement over the state of the art.    


    <span style="color:#900"> **Armin Saadat**, Nima Fathi, Saeed Saadatnejad, Taylor Mordan, Alexandre Alahi</span> 

    <br>
    <br>

    
    
- name: 3D_Seg
  image: images/3D_seg_min.png
  description: |
    ## **Efficient 3D Image Segmentation via Joint Context Completion and 2D Segmentation**
    
    ---
    3D medical image segmentation has typically been tackled with 3D convolutional neural networks. 
    However, these models suffer from high computational costs and GPU memory consumption. 
    In this paper, we propose an improved 2D U-Net model which takes into account dependencies both inside and between 2D slices. 
    Since our model uses only 2D convolutions, it is computationally efficient while achieving better or comparable results to those of 3D segmentation models like 3D U-Net. 
    Moreover, we benefit from test-time adaptation to increase the generalizability and accuracy of our model. 
    We have evaluated our work on the Visceral and CHAOS datasets and got better results compared to 3D U-Net while reducing the training time by a factor of 0.2.


    <span style="color:#900"> **Armin Saadat**, Hossein Khalili, Parnian Zameni, Mahdieh Soleymani Baghshah</span>          
