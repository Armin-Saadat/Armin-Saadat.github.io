- name: 3DPose_Method
  image: images/3D_pose_min.png
  description: |
    ## **3D Human Pose Prediction: Where Do Simple Approaches Stand?**
    
    ---
    3D human pose prediction is a challenging spatio-temporal task that has recently received great attention. 
    Over the past few years, approaches have become increasingly more complex, using Long Short-Term Memories (LSTMs), Graph Convolutional Networks (GCNs), or even Transformers to solve the problem. 
    In this paper, we show that recent models published in top-tier venues still fail to beat a very basic baseline not involving any learning. 
    Then, we argue that some classes of human actions are not easily predictable (even by humans), hence should not be used in the overall learning process. 
    Based on these observations, we propose a simple yet effective LSTM-based encoder-decoder architecture that learns an effective representation for simultaneous prediction of future poses and reconstruction of past ones. 
    We investigate our findings on several standard datasets (Human3.6M, JTA and 3DPW), and obtain a significant improvement over the state of the art.    


    <span style="color:#900"> **Armin Saadat**, Nima Fathi, Saeed Saadatnejad, Taylor Mordan, Alexandre Alahi</span> 
    
    
- name: 3D_Seg
  image: images/unet_rnn.png
  description: |
    ## **Efficient 3D Image Segmentation via Joint Context Completion and 2D Segmentation**
    
    ---
    3D medical image segmentation has typically been tackled with 3D convolutional neural networks(CNN). 
    However, these models suffer from high computational costs and GPU memory consumption. 
    In this paper, we propose an improved 2D U-Net model which takes into account dependencies both inside and between 2D slices. 
    Since our model uses only 2D convolutions, it is computationally efficient while achieving better or comparable results to those of 3D segmentation models like 3D U-Net. 
    Moreover, we benefit from test-time adaptation to increase the generalizability and accuracy of our model. 
    We have evaluated our work on the Visceral and CHAOS datasets and got better results compared to 3D U-Net while reducing the training time by a factor of 0.2.


    <span style="color:#900"> **Armin Saadat**, Hossein Khalili, Parnian Zameni, Mahdieh Soleymani Baghshah</span>          
